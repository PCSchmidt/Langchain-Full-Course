{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Langchain\n",
    "Langchain allows you to interact with your models in a standardized way and lets your easily compose components from langchain to fulfill your special usecase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\users\\pchri\\documents\\learningstuff\\langchain\\venv\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: openai in c:\\users\\pchri\\documents\\learningstuff\\langchain\\venv\\lib\\site-packages (0.27.8)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\pchri\\documents\\learningstuff\\langchain\\venv\\lib\\site-packages (from openai) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\pchri\\documents\\learningstuff\\langchain\\venv\\lib\\site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\pchri\\documents\\learningstuff\\langchain\\venv\\lib\\site-packages (from openai) (3.8.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pchri\\documents\\learningstuff\\langchain\\venv\\lib\\site-packages (from requests>=2.20->openai) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pchri\\documents\\learningstuff\\langchain\\venv\\lib\\site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pchri\\documents\\learningstuff\\langchain\\venv\\lib\\site-packages (from requests>=2.20->openai) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pchri\\documents\\learningstuff\\langchain\\venv\\lib\\site-packages (from requests>=2.20->openai) (2023.5.7)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\pchri\\documents\\learningstuff\\langchain\\venv\\lib\\site-packages (from aiohttp->openai) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\pchri\\documents\\learningstuff\\langchain\\venv\\lib\\site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\pchri\\documents\\learningstuff\\langchain\\venv\\lib\\site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\pchri\\documents\\learningstuff\\langchain\\venv\\lib\\site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\pchri\\documents\\learningstuff\\langchain\\venv\\lib\\site-packages (from aiohttp->openai) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\pchri\\documents\\learningstuff\\langchain\\venv\\lib\\site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\pchri\\documents\\learningstuff\\langchain\\venv\\lib\\site-packages (from tqdm->openai) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv\n",
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(input):\n",
    "    messages = [{\"role\": \"user\", \"content\": input}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of France is Paris.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = chat(\"What is the capital of france\")\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Be very funny when answering questions\n",
      "Question: What is the capital of france\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Oh, that's an easy one! The capital of France is obviously...wait for it...F! Just the letter F. They decided to simplify things and make it easier for everyone. Okay, okay, I'm just kidding. The real answer is Paris. But wouldn't it be funny if it was just the letter F?\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What is the capital of france\"\n",
    "\n",
    "prompt = \"\"\"\n",
    "Be very funny when answering questions\n",
    "Question: {question}\n",
    "\"\"\".format(\n",
    "    question=question\n",
    ")\n",
    "\n",
    "print(prompt)\n",
    "chat(prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
